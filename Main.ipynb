{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b60959-ab54-4761-bd9b-548441698d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69f802-3e75-461f-877b-f84e66dca979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "cath_df = pd.read_csv(\"./data/cath_moments.tsv\", sep='\\t', header=None) # For Train\n",
    "ecod_df = pd.read_csv(\"./data/ecod_moments.tsv\", sep='\\t', header=None) # For eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335379d8-ef5f-46a4-8133-cf786310f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cath_info = cath_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c44bd8-1b74-4d6d-9e61-33d0f52624f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecod_info = ecod_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034cea0c-61c7-4828-88f3-cff10785017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize shapes, classes, and a preview\n",
    "cath_summary = {\n",
    "    \"shape\": cath_df.shape,\n",
    "    \"unique_classes\": cath_df[0].nunique(),\n",
    "    \"class_distribution\": cath_df[0].value_counts(),\n",
    "    \"head\": cath_df.head()\n",
    "}\n",
    "\n",
    "ecod_summary = {\n",
    "    \"shape\": ecod_df.shape,\n",
    "    \"unique_classes\": ecod_df[0].nunique(),\n",
    "    \"class_distribution\": ecod_df[0].value_counts(),\n",
    "    \"head\": ecod_df.head()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be048a6-a9b5-4f6f-ad00-74610b6db555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cath_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86ef59-6d9c-45c0-a371-baa5f02bff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ecod_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d139e8-d1cd-4e48-ae0b-3a476f9bf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    print(type(cath_df.iloc[0,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf19f58-1186-4d6c-8d16-aeccd8ec4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution for CATH\n",
    "cath_class_counts = cath_df[0].value_counts()\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(cath_class_counts, bins=30, edgecolor='black')\n",
    "plt.title('Class Frequency Distribution in CATH Dataset')\n",
    "plt.xlabel('Number of proteins per class')\n",
    "plt.ylabel('Number of classes')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot class distribution for ECOD\n",
    "ecod_class_counts = ecod_df[0].value_counts()\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(ecod_class_counts, bins=20, edgecolor='black')\n",
    "plt.title('Class Frequency Distribution in ECOD Dataset')\n",
    "plt.xlabel('Number of proteins per class')\n",
    "plt.ylabel('Number of classes')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b42ec-a023-45bd-8134-7b4040f6df5a",
   "metadata": {},
   "source": [
    "### Visualizing Class Imbalance\n",
    "\n",
    "Each protein in the dataset is associated with a structural class label (column 0), which identifies its 3D(1D in this case) shape category. Understanding how many proteins fall into each class is critical because the dataset is not balanced—some classes have many proteins, while others have very few.\n",
    "\n",
    "To quantify this, we use `value_counts()` to compute the frequency of each class label and visualize the distribution with a histogram.\n",
    "\n",
    "#### Why this is important:\n",
    "During training, we will create pairs of proteins to determine structural similarity. If a particular class contains many proteins, it will generate significantly more pairs, which may bias the model toward frequently occurring classes. This can lead to overfitting and poor generalization, especially on underrepresented classes.\n",
    "\n",
    "By plotting the class frequency distribution:\n",
    "- We confirm whether class imbalance is present.\n",
    "- We motivate the need for sampling strategies such as `WeightedRandomSampler` to correct for this imbalance during training.\n",
    "\n",
    "This analysis is a key step in understanding the structure of the data and informing how we design the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb5cbce-9fb8-4234-b0fd-d30b6ba80a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b9fca-47ff-4620-b460-0211f1a3617b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338142c3-2c98-4ee9-96f2-0d9c84d40eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1038f8-5421-4a40-9909-f5ba99dc7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import importlib\n",
    "import train\n",
    "import time\n",
    "\n",
    "importlib.reload(train)\n",
    "\n",
    "from train import train_model, test_model_on_ecod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2776cb5-6d19-467e-bd45-3514d3c5f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATH: (2685, 3923), ECOD: (761, 3923)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "cath_df = pd.read_csv(\"./data/cath_moments.tsv\", sep='\\t', header=None).dropna(axis=1)\n",
    "ecod_df = pd.read_csv(\"./data/ecod_moments.tsv\", sep='\\t', header=None).dropna(axis=1)\n",
    "\n",
    "print(f\"CATH: {cath_df.shape}, ECOD: {ecod_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bf336f-01fc-4dd5-9fcf-3eb92b581400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pairwise data from 200 proteins using 12 cores...\n",
      "Flushed buffer 0 with 1 items → ./cache/cath_200/part_0.pkl\n",
      "Flushed buffer 1 with 1000 items → ./cache/cath_200/part_1.pkl\n",
      "Flushed buffer 2 with 1000 items → ./cache/cath_200/part_2.pkl\n",
      "Flushed buffer 3 with 1000 items → ./cache/cath_200/part_3.pkl\n",
      "Flushed buffer 4 with 1000 items → ./cache/cath_200/part_4.pkl\n",
      "Flushed buffer 5 with 1000 items → ./cache/cath_200/part_5.pkl\n",
      "Flushed buffer 6 with 1000 items → ./cache/cath_200/part_6.pkl\n",
      "Flushed buffer 7 with 1000 items → ./cache/cath_200/part_7.pkl\n",
      "Flushed buffer 8 with 1000 items → ./cache/cath_200/part_8.pkl\n",
      "Flushed buffer 9 with 1000 items → ./cache/cath_200/part_9.pkl\n",
      "Flushed buffer 10 with 1000 items → ./cache/cath_200/part_10.pkl\n",
      "Flushed buffer 11 with 1000 items → ./cache/cath_200/part_11.pkl\n",
      "Flushed buffer 12 with 1000 items → ./cache/cath_200/part_12.pkl\n",
      "Flushed buffer 13 with 1000 items → ./cache/cath_200/part_13.pkl\n",
      "Flushed buffer 14 with 1000 items → ./cache/cath_200/part_14.pkl\n",
      "Flushed buffer 15 with 1000 items → ./cache/cath_200/part_15.pkl\n",
      "Flushed buffer 16 with 1000 items → ./cache/cath_200/part_16.pkl\n",
      "Flushed buffer 17 with 1000 items → ./cache/cath_200/part_17.pkl\n",
      "Flushed buffer 18 with 1000 items → ./cache/cath_200/part_18.pkl\n",
      "Flushed buffer 19 with 1000 items → ./cache/cath_200/part_19.pkl\n",
      "Flushed buffer 20 with 899 items → ./cache/cath_200/part_20.pkl\n",
      " Done. Total buffers flushed: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cache_utils import cache_pairwise_data\n",
    "\n",
    "df = pd.read_csv(\"./data/cath_moments.tsv\", sep=\"\\t\", header=None).dropna(axis=1)\n",
    "num_proteins = 200\n",
    "cache_dir = \"./cache/cath_\"+str(num_proteins)\n",
    "cache_pairwise_data(df.head(num_proteins), cache_dir=cache_dir, buffer_limit_mb=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d59ff5-a740-48ee-b385-4e0837857e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 21 parts from ./cache/cath_200 using 16 threads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 21/21 [00:00<00:00, 286.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged total pairs: 19900\n",
      " Saved merged dataset to: ./cache/cath_200/cath_merged.pkl\n",
      "Loaded in  1591.912 ms\n"
     ]
    }
   ],
   "source": [
    "from cache_utils import load_cached_parts,load_and_merge_parts\n",
    "from dataset import ProteinPairDataset\n",
    "\n",
    "tic = time.time_ns()\n",
    "# Step 1: Load and merge buffered part_*.pkl files\n",
    "# features, labels = load_cached_parts(\"cache/cath_buffered\", max_threads=16)\n",
    "\n",
    "#Parallel Load all the parts\n",
    "features, labels = load_and_merge_parts(\n",
    "    cache_dir=cache_dir,\n",
    "    save_path=cache_dir+\"/cath_merged.pkl\", \n",
    "    max_threads=16\n",
    ")\n",
    "\n",
    "tac = time.time_ns()\n",
    "print(\"Loaded in \",(tac-tic)/(10**6),\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2d7be3-0c5b-4910-8814-82e670c13418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Pass them into your dataset directly\n",
    "dataset = ProteinPairDataset(features=features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d786dba6-8f87-42ee-9385-b46e76adb51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected pairs: 19900\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected pairs:\",num_proteins*(num_proteins-1)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62f22498-39de-4671-8a01-96a2ed3b4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu (CPU)\n",
      "Training model (hidden_dim=64) for 5 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vk/4clvfdvn29z3t_m4kf0z2y7c0000gn/T/ipykernel_42371/1393508396.py\", line 8, in <module>\n",
      "    model = train_model(features=features, labels=labels, hidden_dim=64, num_epochs=5)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akshitagarwal/Akshit/UCSD/SP25/rcsb_pdb_nn/train.py\", line 141, in train_model\n",
      "    write.close()\n",
      "    ^^^^^\n",
      "NameError: name 'write' is not defined. Did you mean: 'writer'?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/envs/tf_keras/lib/python3.12/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Optional: re-import the functions explicitly\n",
    "from train import train_model, test_model_on_ecod\n",
    "\n",
    "# # Train logistic regression\n",
    "# model_logistic = train_model(cath_df, hidden_dim=None, num_epochs=5, batch_size=8)\n",
    "\n",
    "# Train small neural net\n",
    "model = train_model(features=features, labels=labels, hidden_dim=64, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3219ae0-a840-4fea-8a0a-9e4487dc7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(features=features, labels=labels, hidden_dim=None, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24485cf1-87ae-4fcc-bad4-b683dda63672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
